
## Motivation

This notebook is part of the requierment for my **data science** Udacity degree. In this project I tried to select a data-set that I had no prior knowledge about to be unbiased and challenging. 

## Usage example

This notebook shows some steps in analysing huge stocks data obtain from Kaggle. It is always challanging to extract  information from many available datapoins, so I tried to adress some major questions in this regards.

## Requierments

The libraries used in this note put are:
1. os,
2. seaborn,
3. pandas,
4. numpy,
5. matplotlib,
6. datetime,
7. pandas_datareader
8. fix_yahoo_finance

## Disclaimer:

This analysis should NOT be taken as financial advice . I have no knowledge of stock trading and good/poor/best terms used to classify companies are based on intuition, which probably is not standard. Needles to say that market complexities cannot be captured by one dimensional price analysis.

## File structure

There is a data folder used in this study tyhat contains *Stock* and *ETFs* folder and a *oil_wti.csv* file. Only Stock Folder and oil_wti.csv has been used in this project.


## References

1. https://www.kaggle.com/borismarjanovic/price-volume-data-for-all-us-stocks-etfs
2. https://datahub.io/core/oil-prices
3. https://en.wikipedia.org/wiki/List_of_S%26P_500_companies
4. https://medium.com/@scienclick/stock-analysis-with-python-61c3418a1d16

